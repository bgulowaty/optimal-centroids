{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimentscommons.nb_parameters import EXPERIMENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    'max_depth': 5,\n",
    "    'n_trees': 5,\n",
    "    \"train_path\": \"../data/processed/breast-train-0-s1.csv\",\n",
    "    \"test_path\": \"../data/processed/breast-test-0-s1.csv\",\n",
    "    \"cv\": 2,\n",
    "    \"cv_repeats\": 5,\n",
    "    \"n_jobs\": -1,\n",
    "    'n_gen': 20,\n",
    "    'pop_size': 100,\n",
    "    'debug': False,\n",
    "    EXPERIMENT_ID: '6'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from box import Box\n",
    "import uuid\n",
    "\n",
    "if 'params' in vars():\n",
    "    params = Box({**DEFAULT_PARAMS, **params})\n",
    "else:\n",
    "    params = Box(DEFAULT_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.start_run(experiment_id=params.EXPERIMENT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(params['train_path'])\n",
    "test_data = pd.read_csv(params['test_path'])\n",
    "x_train = train_data.drop('TARGET', axis=1).values\n",
    "y_train = train_data['TARGET'].values\n",
    "x_test = test_data.drop('TARGET', axis=1).values\n",
    "y_test = test_data['TARGET'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph, KNeighborsClassifier, NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import grouper\n",
    "from itertools import product\n",
    "from scipy.spatial.distance import euclidean\n",
    "from toolz.curried import pipe, reduce, map, filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_with_repeated_elements(input_list, n_repeated):\n",
    "    return [val for val in input_list for _ in range(n_repeated)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rules.classification.utils import covered_by_statements\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_min = np.min(x_train, axis=0)\n",
    "feature_max = np.max(x_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rules.classification.competence_region_ensemble import SimpleCompetenceRegionEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid, NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_wrapper(nn):\n",
    "    return Box({\n",
    "     \"predict\": lambda x: nn.kneighbors(x, n_neighbors=nn.n_samples_fit_, return_distance=False)   \n",
    "    })\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero([3,5,0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator(centroids, depths): \n",
    "    n_trees = centroids.shape[0]\n",
    "    activated_trees_indices = np.nonzero(depths)[0]\n",
    "\n",
    "    active_centroids = centroids[activated_trees_indices]\n",
    "    active_depths = depths[activated_trees_indices]\n",
    "    \n",
    "    space_classifier = NearestNeighbors()\n",
    "    space_classifier.fit(active_centroids)\n",
    "\n",
    "    model = SimpleCompetenceRegionEnsemble(\n",
    "        None,\n",
    "        {label:DecisionTreeClassifier(max_depth=depth, random_state=42) for label, depth in enumerate(active_depths)}\n",
    "    )\n",
    "    \n",
    "    return model, space_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closeset_val(arr, val):\n",
    "    return np.argmin(np.abs(np.array(arr) - val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "\n",
    "Wektor = $[\\text{wspolrzedne}_n, \\text{depth}_n, \\text{wlaczony}_n]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mask(n_trees, n_dimensions):\n",
    "#     return ['real'] * n_dimensions * n_trees + ['real'] * n_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPERATORS = {\n",
    "#     'sampling': {\n",
    "#         'bin': 'bin_random',\n",
    "#         'real': 'real_random',\n",
    "#         'int': 'int_random'\n",
    "#     }, \n",
    "#     'mutation': {\n",
    "#         'bin': 'bin_bitflip',\n",
    "#         'real': 'real_pm',\n",
    "#         'int': 'int_pm',\n",
    "#     },\n",
    "#     'crossover': {\n",
    "#         'bin': 'bin_one_point',\n",
    "#         'real': 'real_sbx',\n",
    "#         'int': 'int_sbx',\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = x_train.shape[1] \n",
    "n_trees = params.n_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.factory import get_sampling, get_crossover, get_mutation\n",
    "# from pymoo.operators.mixed_variable_operator import MixedVariableSampling, MixedVariableMutation, MixedVariableCrossover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = create_mask(n_trees, n_dim)\n",
    "# variable_types = np.unique(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling = MixedVariableSampling(mask, {\n",
    "#     variable_type: get_sampling(OPERATORS['sampling'][variable_type]) for variable_type in variable_types\n",
    "# })\n",
    "# crossover = MixedVariableCrossover(mask, {\n",
    "#     variable_type: get_crossover(OPERATORS['crossover'][variable_type]) for variable_type in variable_types\n",
    "# })\n",
    "# mutation = MixedVariableMutation(mask, {\n",
    "#     variable_type: get_mutation(OPERATORS['mutation'][variable_type]) for variable_type in variable_types\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from toolz.curried import pipe, map, reduce, filter\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "class MyProblem(ElementwiseProblem):\n",
    "\n",
    "    def __init__(self, n_trees, x_train, y_train, max_tree_depth, **kwargs):\n",
    "        n_dim = x_train.shape[1]\n",
    "        \n",
    "        super().__init__(\n",
    "            n_var=n_trees*n_dim + n_trees, # each centroid * number of features + depths + on/off\n",
    "             n_obj=1, # accuracy\n",
    "             n_constr=0,\n",
    "             xl=list(np.min(x_train, axis=0)) * n_trees + n_trees * [-0.5],\n",
    "             xu=list(np.max(x_train, axis=0)) * n_trees + n_trees * [max_tree_depth + 0.5],\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.n_trees = n_trees\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.n_dim = n_dim\n",
    "        self.max_tree_depth = max_tree_depth\n",
    "        \n",
    "    def _evaluate(self, individual, out, *args, **kwargs):\n",
    "        n_coordinates_in_individual = self.n_dim * self.n_trees\n",
    "        centroid_coordinates = individual[:n_coordinates_in_individual]\n",
    "        \n",
    "        individual_as_centroids = pipe(\n",
    "            centroid_coordinates,\n",
    "            lambda x: grouper(x, self.n_dim),\n",
    "            list,\n",
    "            np.array,\n",
    "            np.nan_to_num\n",
    "        )\n",
    "        \n",
    "        tree_depths_continous = individual[-self.n_trees:]\n",
    "        possible_tree_depths = list(range(self.max_tree_depth + 1))\n",
    "        \n",
    "        tree_depths = np.array([find_closeset_val(possible_tree_depths, td) for td in tree_depths_continous])\n",
    "\n",
    "        if np.all(tree_depths==0):\n",
    "            out[\"F\"] = 1\n",
    "        else:\n",
    "            model, space_classifier = create_estimator(individual_as_centroids, tree_depths)\n",
    "\n",
    "            skf = RepeatedKFold(n_splits=params['cv'], n_repeats=params['cv_repeats'], random_state=42)\n",
    "            scores = cross_validate(model, self.x_train, self.y_train, n_jobs=params['n_jobs'], scoring='accuracy', cv=skf, fit_params={\n",
    "            'competence_region_classifier': nn_wrapper(space_classifier)\n",
    "            })\n",
    "            \n",
    "            if params.debug:\n",
    "                print(f\"Depths = {tree_depths}, acc = {scores['test_score'].mean()}\")\n",
    "\n",
    "            out[\"F\"] = 1 - scores['test_score'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "from pymoo.core.problem import starmap_parallelized_eval\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "\n",
    "pool = ThreadPool(params['pop_size'])\n",
    "\n",
    "problem = MyProblem(params.n_trees, x_train, y_train, params.max_depth, \n",
    "                    runner=pool.starmap, func_eval=starmap_parallelized_eval\n",
    "                   )\n",
    "\n",
    " \n",
    "res = minimize(problem,\n",
    "           GA(\n",
    "               pop_size=params['pop_size'],\n",
    "               verbose=True,\n",
    "               seed=42,\n",
    "                eliminate_duplicates=True\n",
    "           ),\n",
    "           (\"n_gen\", params['n_gen']),\n",
    "           verbose=True,\n",
    "               save_history=True,\n",
    "           seed=42)\n",
    "\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.exec_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val = [np.average(e.pop.get(\"F\")) for e in res.history]\n",
    "plt.plot(np.arange(len(val)), val)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, vals in enumerate([e.pop.get(\"F\") for e in res.history]):\n",
    "    mlflow.log_metrics(\n",
    "        {'min_function_value': np.min(vals), \n",
    "         'avg_function_value': np.average(vals),\n",
    "         'max_function_value': np.max(vals)\n",
    "        }, step=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if res.X.ndim == 1:\n",
    "    pareto_front = [res.X]\n",
    "else:\n",
    "    pareto_front = res.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "for individual in pareto_front:\n",
    "    n_coordinates_in_individual = n_dim * n_trees\n",
    "    centroid_coordinates = individual[:n_coordinates_in_individual]\n",
    "\n",
    "    individual_as_centroids = pipe(\n",
    "        centroid_coordinates,\n",
    "        lambda x: grouper(x, n_dim),\n",
    "        list,\n",
    "        np.array,\n",
    "        np.nan_to_num\n",
    "    )\n",
    "        \n",
    "    tree_depths_continous = individual[-n_trees:]\n",
    "    possible_tree_depths = list(range(params.max_depth + 1))\n",
    "        \n",
    "    tree_depths = np.array([find_closeset_val(possible_tree_depths, td) for td in tree_depths_continous])\n",
    "\n",
    "    if params.debug:\n",
    "        print(f\"Depths = {tree_depths}\")\n",
    "\n",
    "    if np.all(tree_depths==0):\n",
    "        continue\n",
    "    else:\n",
    "        model, space_classifier = create_estimator(individual_as_centroids, tree_depths)\n",
    "        model.fit(x_train, y_train, competence_region_classifier=nn_wrapper(space_classifier))\n",
    "    \n",
    "        accs.append(accuracy_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric('best_training_model_acc', 1 - min(res.F))\n",
    "mlflow.log_metric('best_model_acc', max(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_param(\"centroids\", json.dumps(individual_as_centroids.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
